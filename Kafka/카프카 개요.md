# 카프카 개요
- 토픽은 파티션으로 구성된 일련의 로그 파일
- 카프카의 안정된 성능 + 병렬 성능의 핵심은 파티션 -> 분산 처리로 이어진다
- RDBMS로 생각하면 테이블과 유사하다
  - but update 없음
  - 계속해서 순차적으로 append만 가능하다 
- distributable, immutable, partitioned
- 파티션 여러 개일 수 있고, 그 안에 오프셋이 할당되는 방식이다.
- 브로커 안에 토픽이 있고 그 안에 파티션이 또 여러개가 있다.
- 브로커도 여러 개가 있을 수 있다. 하드웨어적으로 멀티 노드 브로커를 사용할 수 있다. (클러스터 안에서)

# 분산 시스템
- replication-factor 라는 요소를 통해서
- 브로커 별로 복제된 파티션을 가지게 할 수 있다. 
- 정합성을 유지하기 위해서이며, 하나의 브로커가 죽어도 가용성을 보정한다.

# CLI 커맨드 알아보기
~~~
# 카프카 커맨드, 서버 주소, 생성한다, 토픽을, 이름, 파티션 갯수
$ kafka-topics --bootstrap-server localhost:9092 --create --topic 이름 --partitions 3 

# 인자 설명
--bootstrap-server: 위의 커맨드의 경우, 토픽을 생성할 서버 주소
--create: 생성할 토픽, 파티션 개수, replication 개수가 이어서 붙는다
--list: 브로커에 있는 토픽들의 리스트
--describe: 상세 정보 표시를 하는데, --topic이 붙어 토픽명을 기술하면 그것에 대한 정보
-- partitions {숫자}: {숫자} 개수만큼 replication을 만든다. (server.properties, num.partitions에서 defaultn 값 설정 가능)
--replication-factor {숫자}: 브로커 숫자에 맞춰서 넣는다. 현재는 브로커가 1개라서 2개 이상 불가능.

# 삭제
$ kafka-topics --bootstrap-server localhost:9092 --delete --topic {토픽 이름}
~~~

- data 폴더를 따로 지정했으므로, 상기 방법으로 만들어진 토픽들이 data 폴더 안에 생긱ㄴ 것을 확인할 수 있다

# Producer 개요
- 토픽에 메시지를 보내는 역할
  - 시계 활성 기반으로 로그 파일에 기록
- 성능/로드밸런싱/가용성/정합성 등을 고려하여 어떤 브로커의 어떤 파티션으로 메시지를 쓸지 전략적으로 결정하게 된다
- 자바 기반으로 보낸다면 ProducerRecord 객체를 보내며 아래로 구성되어있다. (* 필수 값)
  - Topic *
  - Partition
  - Key
  - Value *
  - Header
  
### send() 메소드 호출 프로세스
- ProducerRecord는 Serializer와 Partitioner를 거쳐서 파티션에 저장한다.
- 파티션에 저장되는 데이터는 배치로 구성된다.
- 별도의 스레드가 생성되면서 send
- 실패, 성공이냐 따라서 재시도를 결정하는 프로세스를 포함한다

# Consumer
- Subscribe & Poll을 통해서 메시지를 읽어들인다
- 여러 consumer가 존재하는 경우 어떤 브로커의 어떤 파티션에서 메시지를 어떻게 읽을지 전략적으로 결정한다.

### subscribe, poll, commit
- subscribe()로 어떤 브로커의 어떤 토픽을 보고 있음
- poll()을 하게 되면 offset을 통해서 가져오는데
- 어디까지 읽어들였는지를 commit을 통해서 기록하는 형태

# 실습
- 테스트/디버깅 용도로 kafka-console-producerdhk kafka-console-consumer를 제공한다
- console 상에서 커맨드를 통해 producer의 메시지 전송과 consumer의 메시지 읽기를 수행해본다.